{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Г2 Нейронные сети в 3D данных\n",
    "    выполнил Сергей Харитонов МИВТ-221\n",
    "\n",
    "# Задание\n",
    "Задание творческое. По адресу https://drive.google.com/drive/folders/1BQQtdUAj9t0pWBN4rld8geKpv9sqv6Ik?usp=sharing лежат данные размеченные двумя классами и уже разбитые на тестовые и тренировочные. Применить нейронную сеть с указанной в варианте архитектурой и описать полученные результаты.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import layers, regularizers, initializers, optimizers, Input, Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Загрузка облаков точек в память"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "DIR_PATH = os.getcwd()\n",
    "DATA_PATH = os.path.join(DIR_PATH, 'data')\n",
    "\n",
    "\n",
    "def load_data(entity: str, type_data: str) -> [[float]]:\n",
    "    path = os.path.join(DATA_PATH, entity, type_data)\n",
    "    files_paths = os.listdir(path)\n",
    "\n",
    "    result = []\n",
    "    for file_path in map(lambda file_path: os.path.join(path, file_path), files_paths):\n",
    "        with open(file_path) as f:\n",
    "            result.append([\n",
    "                list(map(float, row.split()))\n",
    "                for row in f.readlines()\n",
    "            ])\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "bathtub_train = load_data('bathtub', 'train')\n",
    "bathtub_test = load_data('bathtub', 'test')\n",
    "\n",
    "berth_wall_train = load_data('berth_wall', 'train')\n",
    "berth_wall_test = load_data('berth_wall', 'test')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Описание выборок для обучения и теста, а так же необходимых констант"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Образов для обучения: 2672\n",
      "Образов для обучения 1 типа bathtub: 392\n",
      "Образов для обучения 2 типа berthwall: 2280\n",
      "\n",
      "Образов для валидации: 675\n",
      "Образов для валидации 1 типа bathtub: 167\n",
      "Образов для валидации 2 типа berthwall: 508\n"
     ]
    }
   ],
   "source": [
    "# Размер скользящего окна по файлу с данными\n",
    "NUM_POINTS = 2000\n",
    "# Количество классов для классификации\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "\n",
    "def get_data(data_rows: [[float]], flag: int):\n",
    "    result = []\n",
    "    for row in data_rows:\n",
    "        while len(row) >= NUM_POINTS:\n",
    "            result.append(row[:NUM_POINTS + 1])\n",
    "            row = row[NUM_POINTS + 1:]\n",
    "    return [(row, flag) for row in result]\n",
    "\n",
    "\n",
    "train = get_data(bathtub_train, 1) + get_data(berth_wall_train, 2)\n",
    "test = get_data(bathtub_test, 1) + get_data(berth_wall_test, 2)\n",
    "\n",
    "shuffle(train)\n",
    "\n",
    "\n",
    "def print_stat(dataset, for_some):\n",
    "    print(f'Образов для {for_some}: {len(dataset)}')\n",
    "    print(f'Образов для {for_some} 1 типа bathtub: {len(list(filter(lambda row: row[1] == 1, dataset)))}')\n",
    "    print(f'Образов для {for_some} 2 типа berthwall: {len(list(filter(lambda row: row[1] == 2, dataset)))}')\n",
    "\n",
    "\n",
    "train_x, train_y = list(zip(*train))\n",
    "test_x, test_y = list(zip(*test))\n",
    "\n",
    "print_stat(train, 'обучения')\n",
    "print()\n",
    "print_stat(test, 'валидации')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Описание модели\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"pointnet\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 2000, 3)]            0         []                            \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)             (None, 2000, 32)             128       ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (None, 2000, 32)             128       ['conv1d[0][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation (Activation)     (None, 2000, 32)             0         ['batch_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)           (None, 2000, 64)             2112      ['activation[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_1 (Bat  (None, 2000, 64)             256       ['conv1d_1[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_1 (Activation)   (None, 2000, 64)             0         ['batch_normalization_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)           (None, 2000, 512)            33280     ['activation_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_2 (Bat  (None, 2000, 512)            2048      ['conv1d_2[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_2 (Activation)   (None, 2000, 512)            0         ['batch_normalization_2[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " global_max_pooling1d (Glob  (None, 512)                  0         ['activation_2[0][0]']        \n",
      " alMaxPooling1D)                                                                                  \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 256)                  131328    ['global_max_pooling1d[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_3 (Bat  (None, 256)                  1024      ['dense[0][0]']               \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_3 (Activation)   (None, 256)                  0         ['batch_normalization_3[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 128)                  32896     ['activation_3[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_4 (Bat  (None, 128)                  512       ['dense_1[0][0]']             \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_4 (Activation)   (None, 128)                  0         ['batch_normalization_4[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 9)                    1161      ['activation_4[0][0]']        \n",
      "                                                                                                  \n",
      " reshape (Reshape)           (None, 3, 3)                 0         ['dense_2[0][0]']             \n",
      "                                                                                                  \n",
      " dot (Dot)                   (None, 2000, 3)              0         ['input_1[0][0]',             \n",
      "                                                                     'reshape[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)           (None, 2000, 32)             128       ['dot[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (Bat  (None, 2000, 32)             128       ['conv1d_3[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_5 (Activation)   (None, 2000, 32)             0         ['batch_normalization_5[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)           (None, 2000, 32)             1056      ['activation_5[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_6 (Bat  (None, 2000, 32)             128       ['conv1d_4[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_6 (Activation)   (None, 2000, 32)             0         ['batch_normalization_6[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)           (None, 2000, 32)             1056      ['activation_6[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_7 (Bat  (None, 2000, 32)             128       ['conv1d_5[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_7 (Activation)   (None, 2000, 32)             0         ['batch_normalization_7[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)           (None, 2000, 64)             2112      ['activation_7[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_8 (Bat  (None, 2000, 64)             256       ['conv1d_6[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_8 (Activation)   (None, 2000, 64)             0         ['batch_normalization_8[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)           (None, 2000, 512)            33280     ['activation_8[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_9 (Bat  (None, 2000, 512)            2048      ['conv1d_7[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_9 (Activation)   (None, 2000, 512)            0         ['batch_normalization_9[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " global_max_pooling1d_1 (Gl  (None, 512)                  0         ['activation_9[0][0]']        \n",
      " obalMaxPooling1D)                                                                                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 256)                  131328    ['global_max_pooling1d_1[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " batch_normalization_10 (Ba  (None, 256)                  1024      ['dense_3[0][0]']             \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_10 (Activation)  (None, 256)                  0         ['batch_normalization_10[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 128)                  32896     ['activation_10[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_11 (Ba  (None, 128)                  512       ['dense_4[0][0]']             \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_11 (Activation)  (None, 128)                  0         ['batch_normalization_11[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 1024)                 132096    ['activation_11[0][0]']       \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)         (None, 32, 32)               0         ['dense_5[0][0]']             \n",
      "                                                                                                  \n",
      " dot_1 (Dot)                 (None, 2000, 32)             0         ['activation_6[0][0]',        \n",
      "                                                                     'reshape_1[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_8 (Conv1D)           (None, 2000, 32)             1056      ['dot_1[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_12 (Ba  (None, 2000, 32)             128       ['conv1d_8[0][0]']            \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_12 (Activation)  (None, 2000, 32)             0         ['batch_normalization_12[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_9 (Conv1D)           (None, 2000, 64)             2112      ['activation_12[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_13 (Ba  (None, 2000, 64)             256       ['conv1d_9[0][0]']            \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_13 (Activation)  (None, 2000, 64)             0         ['batch_normalization_13[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_10 (Conv1D)          (None, 2000, 512)            33280     ['activation_13[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_14 (Ba  (None, 2000, 512)            2048      ['conv1d_10[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_14 (Activation)  (None, 2000, 512)            0         ['batch_normalization_14[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " global_max_pooling1d_2 (Gl  (None, 512)                  0         ['activation_14[0][0]']       \n",
      " obalMaxPooling1D)                                                                                \n",
      "                                                                                                  \n",
      " dense_6 (Dense)             (None, 256)                  131328    ['global_max_pooling1d_2[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " batch_normalization_15 (Ba  (None, 256)                  1024      ['dense_6[0][0]']             \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_15 (Activation)  (None, 256)                  0         ['batch_normalization_15[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 256)                  0         ['activation_15[0][0]']       \n",
      "                                                                                                  \n",
      " dense_7 (Dense)             (None, 128)                  32896     ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_16 (Ba  (None, 128)                  512       ['dense_7[0][0]']             \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_16 (Activation)  (None, 128)                  0         ['batch_normalization_16[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 128)                  0         ['activation_16[0][0]']       \n",
      "                                                                                                  \n",
      " dense_8 (Dense)             (None, 2)                    258       ['dropout_1[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 747947 (2.85 MB)\n",
      "Trainable params: 741867 (2.83 MB)\n",
      "Non-trainable params: 6080 (23.75 KB)\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def conv_bn(x, filters):\n",
    "    x = layers.Conv1D(filters, kernel_size=1, padding=\"valid\")(x)\n",
    "    x = layers.BatchNormalization(momentum=0.0)(x)\n",
    "    return layers.Activation(\"relu\")(x)\n",
    "\n",
    "\n",
    "def dense_bn(x, filters):\n",
    "    x = layers.Dense(filters)(x)\n",
    "    x = layers.BatchNormalization(momentum=0.0)(x)\n",
    "    return layers.Activation(\"relu\")(x)\n",
    "\n",
    "\n",
    "class OrthogonalRegularizer(regularizers.Regularizer):\n",
    "    def __init__(self, num_features, l2reg=0.001):\n",
    "        self.num_features = num_features\n",
    "        self.l2reg = l2reg\n",
    "        self.eye = tf.eye(num_features)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = tf.reshape(x, (-1, self.num_features, self.num_features))\n",
    "        xxt = tf.tensordot(x, x, axes=(2, 2))\n",
    "        xxt = tf.reshape(xxt, (-1, self.num_features, self.num_features))\n",
    "        return tf.reduce_sum(self.l2reg * tf.square(xxt - self.eye))\n",
    "\n",
    "\n",
    "def tnet(inputs, num_features):\n",
    "    bias = initializers.Constant(np.eye(num_features).flatten())\n",
    "    reg = OrthogonalRegularizer(num_features)\n",
    "\n",
    "    x = conv_bn(inputs, 32)\n",
    "    x = conv_bn(x, 64)\n",
    "    x = conv_bn(x, 512)\n",
    "    x = layers.GlobalMaxPooling1D()(x)\n",
    "    x = dense_bn(x, 256)\n",
    "    x = dense_bn(x, 128)\n",
    "    x = layers.Dense(\n",
    "        num_features * num_features,\n",
    "        kernel_initializer=\"zeros\",\n",
    "        bias_initializer=bias,\n",
    "        activity_regularizer=reg,\n",
    "    )(x)\n",
    "    feat_T = layers.Reshape((num_features, num_features))(x)\n",
    "    return layers.Dot(axes=(2, 1))([inputs, feat_T])\n",
    "\n",
    "\n",
    "inputs = Input(shape=(NUM_POINTS, 3))\n",
    "\n",
    "x = tnet(inputs, 3)\n",
    "x = conv_bn(x, 32)\n",
    "x = conv_bn(x, 32)\n",
    "x = tnet(x, 32)\n",
    "x = conv_bn(x, 32)\n",
    "x = conv_bn(x, 64)\n",
    "x = conv_bn(x, 512)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = dense_bn(x, 256)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = dense_bn(x, 128)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "\n",
    "outputs = layers.Dense(NUM_CLASSES, activation=\"softmax\")(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs, name=\"pointnet\")\n",
    "print(model.summary())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Сборка модели и обучение"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 7\u001B[0m\n\u001B[1;32m      1\u001B[0m model\u001B[38;5;241m.\u001B[39mcompile(\n\u001B[1;32m      2\u001B[0m     loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msparse_categorical_crossentropy\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      3\u001B[0m     optimizer\u001B[38;5;241m=\u001B[39moptimizers\u001B[38;5;241m.\u001B[39mAdam(learning_rate\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.001\u001B[39m),\n\u001B[1;32m      4\u001B[0m     metrics\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msparse_categorical_accuracy\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m      5\u001B[0m )\n\u001B[0;32m----> 7\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_x\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_y\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     10\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m20\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     11\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     12\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtrain_x\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_y\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     13\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.2/envs/deeplearning/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.2/envs/deeplearning/lib/python3.10/site-packages/keras/src/engine/training.py:1682\u001B[0m, in \u001B[0;36mModel.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1672\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_cluster_coordinator \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m   1673\u001B[0m         tf\u001B[38;5;241m.\u001B[39mdistribute\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mcoordinator\u001B[38;5;241m.\u001B[39mClusterCoordinator(\n\u001B[1;32m   1674\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdistribute_strategy\n\u001B[1;32m   1675\u001B[0m         )\n\u001B[1;32m   1676\u001B[0m     )\n\u001B[1;32m   1678\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdistribute_strategy\u001B[38;5;241m.\u001B[39mscope(), training_utils\u001B[38;5;241m.\u001B[39mRespectCompiledTrainableState(  \u001B[38;5;66;03m# noqa: E501\u001B[39;00m\n\u001B[1;32m   1679\u001B[0m     \u001B[38;5;28mself\u001B[39m\n\u001B[1;32m   1680\u001B[0m ):\n\u001B[1;32m   1681\u001B[0m     \u001B[38;5;66;03m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001B[39;00m\n\u001B[0;32m-> 1682\u001B[0m     data_handler \u001B[38;5;241m=\u001B[39m \u001B[43mdata_adapter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_data_handler\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1683\u001B[0m \u001B[43m        \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1684\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1685\u001B[0m \u001B[43m        \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1686\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1687\u001B[0m \u001B[43m        \u001B[49m\u001B[43msteps_per_epoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msteps_per_epoch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1688\u001B[0m \u001B[43m        \u001B[49m\u001B[43minitial_epoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minitial_epoch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1689\u001B[0m \u001B[43m        \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1690\u001B[0m \u001B[43m        \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshuffle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1691\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclass_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclass_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1692\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_queue_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_queue_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1693\u001B[0m \u001B[43m        \u001B[49m\u001B[43mworkers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mworkers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1694\u001B[0m \u001B[43m        \u001B[49m\u001B[43muse_multiprocessing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_multiprocessing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1695\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1696\u001B[0m \u001B[43m        \u001B[49m\u001B[43msteps_per_execution\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_steps_per_execution\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1697\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1699\u001B[0m     \u001B[38;5;66;03m# Container that configures and calls `tf.keras.Callback`s.\u001B[39;00m\n\u001B[1;32m   1700\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(callbacks, callbacks_module\u001B[38;5;241m.\u001B[39mCallbackList):\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.2/envs/deeplearning/lib/python3.10/site-packages/keras/src/engine/data_adapter.py:1678\u001B[0m, in \u001B[0;36mget_data_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m   1676\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m _ClusterCoordinatorExactEvalDataHandler(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1677\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _ClusterCoordinatorDataHandler(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m-> 1678\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mDataHandler\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.2/envs/deeplearning/lib/python3.10/site-packages/keras/src/engine/data_adapter.py:1284\u001B[0m, in \u001B[0;36mDataHandler.__init__\u001B[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute, pss_evaluation_shards)\u001B[0m\n\u001B[1;32m   1281\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1282\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_steps_per_execution \u001B[38;5;241m=\u001B[39m steps_per_execution\n\u001B[0;32m-> 1284\u001B[0m adapter_cls \u001B[38;5;241m=\u001B[39m \u001B[43mselect_data_adapter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1285\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_adapter \u001B[38;5;241m=\u001B[39m adapter_cls(\n\u001B[1;32m   1286\u001B[0m     x,\n\u001B[1;32m   1287\u001B[0m     y,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1298\u001B[0m     pss_evaluation_shards\u001B[38;5;241m=\u001B[39mpss_evaluation_shards,\n\u001B[1;32m   1299\u001B[0m )\n\u001B[1;32m   1301\u001B[0m strategy \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mdistribute\u001B[38;5;241m.\u001B[39mget_strategy()\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.2/envs/deeplearning/lib/python3.10/site-packages/keras/src/engine/data_adapter.py:1102\u001B[0m, in \u001B[0;36mselect_data_adapter\u001B[0;34m(x, y)\u001B[0m\n\u001B[1;32m   1100\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mselect_data_adapter\u001B[39m(x, y):\n\u001B[1;32m   1101\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Selects a data adapter that can handle a given x and y.\"\"\"\u001B[39;00m\n\u001B[0;32m-> 1102\u001B[0m     adapter_cls \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mcls\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m \u001B[38;5;28mcls\u001B[39m \u001B[38;5;129;01min\u001B[39;00m ALL_ADAPTER_CLS \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39mcan_handle(x, y)]\n\u001B[1;32m   1103\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m adapter_cls:\n\u001B[1;32m   1104\u001B[0m         \u001B[38;5;66;03m# TODO(scottzhu): This should be a less implementation-specific error.\u001B[39;00m\n\u001B[1;32m   1105\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1106\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFailed to find data adapter that can handle input: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m, \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m   1107\u001B[0m                 _type_name(x), _type_name(y)\n\u001B[1;32m   1108\u001B[0m             )\n\u001B[1;32m   1109\u001B[0m         )\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.2/envs/deeplearning/lib/python3.10/site-packages/keras/src/engine/data_adapter.py:1102\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m   1100\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mselect_data_adapter\u001B[39m(x, y):\n\u001B[1;32m   1101\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Selects a data adapter that can handle a given x and y.\"\"\"\u001B[39;00m\n\u001B[0;32m-> 1102\u001B[0m     adapter_cls \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mcls\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m \u001B[38;5;28mcls\u001B[39m \u001B[38;5;129;01min\u001B[39;00m ALL_ADAPTER_CLS \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcan_handle\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m]\n\u001B[1;32m   1103\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m adapter_cls:\n\u001B[1;32m   1104\u001B[0m         \u001B[38;5;66;03m# TODO(scottzhu): This should be a less implementation-specific error.\u001B[39;00m\n\u001B[1;32m   1105\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1106\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFailed to find data adapter that can handle input: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m, \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m   1107\u001B[0m                 _type_name(x), _type_name(y)\n\u001B[1;32m   1108\u001B[0m             )\n\u001B[1;32m   1109\u001B[0m         )\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.2/envs/deeplearning/lib/python3.10/site-packages/keras/src/engine/data_adapter.py:614\u001B[0m, in \u001B[0;36mCompositeTensorDataAdapter.can_handle\u001B[0;34m(x, y)\u001B[0m\n\u001B[1;32m    611\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    612\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _is_composite(v)\n\u001B[0;32m--> 614\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43many\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m_is_composite\u001B[49m\u001B[43m(\u001B[49m\u001B[43mv\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mv\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mflat_inputs\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mall\u001B[39m(\n\u001B[1;32m    615\u001B[0m     _is_tensor_or_composite(v) \u001B[38;5;28;01mfor\u001B[39;00m v \u001B[38;5;129;01min\u001B[39;00m flat_inputs\n\u001B[1;32m    616\u001B[0m )\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.2/envs/deeplearning/lib/python3.10/site-packages/keras/src/engine/data_adapter.py:614\u001B[0m, in \u001B[0;36m<genexpr>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    611\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    612\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _is_composite(v)\n\u001B[0;32m--> 614\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28many\u001B[39m(\u001B[43m_is_composite\u001B[49m\u001B[43m(\u001B[49m\u001B[43mv\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m v \u001B[38;5;129;01min\u001B[39;00m flat_inputs) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mall\u001B[39m(\n\u001B[1;32m    615\u001B[0m     _is_tensor_or_composite(v) \u001B[38;5;28;01mfor\u001B[39;00m v \u001B[38;5;129;01min\u001B[39;00m flat_inputs\n\u001B[1;32m    616\u001B[0m )\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.2/envs/deeplearning/lib/python3.10/site-packages/keras/src/engine/data_adapter.py:607\u001B[0m, in \u001B[0;36mCompositeTensorDataAdapter.can_handle.<locals>._is_composite\u001B[0;34m(v)\u001B[0m\n\u001B[1;32m    605\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    606\u001B[0m \u001B[38;5;66;03m# Support Scipy sparse tensors if scipy is installed\u001B[39;00m\n\u001B[0;32m--> 607\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_is_scipy_sparse\u001B[49m\u001B[43m(\u001B[49m\u001B[43mv\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.2/envs/deeplearning/lib/python3.10/site-packages/keras/src/engine/data_adapter.py:1962\u001B[0m, in \u001B[0;36m_is_scipy_sparse\u001B[0;34m(x)\u001B[0m\n\u001B[1;32m   1960\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_is_scipy_sparse\u001B[39m(x):\n\u001B[1;32m   1961\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1962\u001B[0m         \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mscipy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msparse\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m issparse\n\u001B[1;32m   1964\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m issparse(x)\n\u001B[1;32m   1965\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m:\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:1027\u001B[0m, in \u001B[0;36m_find_and_load\u001B[0;34m(name, import_)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:1002\u001B[0m, in \u001B[0;36m_find_and_load_unlocked\u001B[0;34m(name, import_)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:945\u001B[0m, in \u001B[0;36m_find_spec\u001B[0;34m(name, path, target)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap_external>:1430\u001B[0m, in \u001B[0;36mfind_spec\u001B[0;34m(cls, fullname, path, target)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap_external>:1402\u001B[0m, in \u001B[0;36m_get_spec\u001B[0;34m(cls, fullname, path, target)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap_external>:1535\u001B[0m, in \u001B[0;36mfind_spec\u001B[0;34m(self, fullname, target)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap_external>:147\u001B[0m, in \u001B[0;36m_path_stat\u001B[0;34m(path)\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.legacy.Adam,\n",
    "    metrics=[\"sparse_categorical_accuracy\"],\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_x,\n",
    "    train_y,\n",
    "    epochs=20,\n",
    "    verbose=1,\n",
    "    validation_data=(train_x, train_y)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Вывод\n",
    "В ходе обучения сверточной сети были получены высокие результаты распознования\n",
    "для цветных изображений - 99%\n",
    "для чернобелых -98%\n",
    "\n",
    "Так же было замечено, что время затрачиваемое на обучение на чернобелых изображений в десятки раз меньше при не значительной разнице в качестве распознавания\n",
    "для цветных изображений - 0:04:07.880184\n",
    "для чернобелых - 0:00:11.075703\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
